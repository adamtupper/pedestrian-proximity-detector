{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a COCO-style Dataset for the Supervisely Persons Dataset\n",
    "\n",
    "A COCO-style dataset is required for training Facebook's Mask R-CNN model implementation. This notebook explores and tests an approach for generating a COCO-style dataset for the Supervisely Persons dataset. This is accomplished through the use of the [pycococreatortools](https://github.com/waspinator/pycococreator/) package.\n",
    "\n",
    "A standalone script `supervisely_to_coco.py` will be created based on this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import fnmatch\n",
    "import math\n",
    "import zlib\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycococreatortools import pycococreatortools\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO = {\n",
    "    \"description\": \"Supervisely Persons Dataset\",\n",
    "    \"url\": \"https://supervise.ly/\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2018,\n",
    "    \"contributor\": \"Supervisely\",\n",
    "    \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"\",\n",
    "        \"url\": \"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\n",
    "        'id': 1,\n",
    "        'name': 'person',\n",
    "        'supercategory': 'object',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Required Inputs\n",
    "\n",
    "To generate a COCO-style dataset, we require:\n",
    "    \n",
    "- The path to the parent directory of the Supervisely Persons dataset (this is where the COCO-style dataset will be saved).\n",
    "- The name of the directory containing the Supervisly Persons dataset (in the same structure as downloaded).\n",
    "- A plain text file containing the `<subset>/<filename>` of each example (generated by `create_supervisely_examples_list.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/media/adam/HDD Storage/Datasets'\n",
    "dataset_dir = 'supervisely-persons' # Relative to root\n",
    "example_file = 'trainval.txt' # Relative to dataset directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Train and Test Sets\n",
    "\n",
    "Divide the examples into a 70%-30% split for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997 train images. 1714 test images.\n"
     ]
    }
   ],
   "source": [
    "# Read in list of examples\n",
    "with open(os.path.join(parent_dir, dataset_dir, example_file)) as f:\n",
    "    examples = [x.strip() for x in f.readlines()]\n",
    "\n",
    "# Split examples into train and test sets\n",
    "random.seed(1)\n",
    "random.shuffle(examples)\n",
    "num_train_examples = math.floor(0.7 * len(examples))\n",
    "num_test_examples = len(examples) - num_train_examples\n",
    "train_examples = examples[:num_train_examples]\n",
    "test_examples = examples[num_train_examples:]\n",
    "print(f'{num_train_examples} train images. {num_test_examples} test images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Output Directories for the COCO-style Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(parent_dir, dataset_dir + '-coco')\n",
    "os.mkdir(output_dir)\n",
    "os.mkdir(os.path.join(output_dir, 'annotations'))\n",
    "os.mkdir(os.path.join(output_dir, 'image-train'))\n",
    "os.mkdir(os.path.join(output_dir, 'image-test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate a COCO-style Dataset\n",
    "\n",
    "This functionality will be used to create train and test example sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base64_2_mask(s):\n",
    "    \"\"\"\n",
    "    Convert from a base64 encoded string to numpy mask.\n",
    "    \n",
    "    Provided by Supervisely.\n",
    "    \"\"\"\n",
    "    z = zlib.decompress(base64.b64decode(s))\n",
    "    n = np.frombuffer(z, np.uint8)\n",
    "    mask = cv.imdecode(n, cv.IMREAD_UNCHANGED)[:, :, 3].astype(bool)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def mask_2_base64(mask):\n",
    "    \"\"\"\n",
    "    Convert from a numpy mask to a base64 encoded string.\n",
    "    \n",
    "    Provided by Supervisely.\n",
    "    \"\"\"\n",
    "    img_pil = Image.fromarray(np.array(mask, dtype=np.uint8))\n",
    "    img_pil.putpalette([0,0,0,255,255,255])\n",
    "    bytes_io = io.BytesIO()\n",
    "    img_pil.save(bytes_io, format='PNG', transparency=0, optimize=0)\n",
    "    bytes = bytes_io.getvalue()\n",
    "    \n",
    "    return base64.b64encode(zlib.compress(bytes)).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coco_dataset(info, licenses, categories, examples, dataset_path, output_path, train=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define COCO output template\n",
    "    coco_output = {\n",
    "        \"info\": info,\n",
    "        \"licenses\": licenses,\n",
    "        \"categories\": categories,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    # Add examples to the COCO output\n",
    "    instance_id = 1\n",
    "    for example_id, example in enumerate(examples):\n",
    "        mask_found = False\n",
    "        subset, filename = example.split('/')\n",
    "        \n",
    "        annotation_file_path = os.path.join(dataset_path, subset, 'ann', filename + '.json')\n",
    "        with open(annotation_file_path) as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        image_height = annotations['size']['height']\n",
    "        image_width = annotations['size']['width']\n",
    "        \n",
    "        for instance in annotations['objects']:\n",
    "            if instance['classTitle'] == 'person_bmp': # Only BMP masks are compatible with pycococreatortools\n",
    "\n",
    "                # Create whole image mask\n",
    "                mask = base64_2_mask(instance['bitmap']['data'])\n",
    "                mask_origin = instance['bitmap']['origin']\n",
    "                mask_height, mask_width = mask.shape\n",
    "\n",
    "                left_pad = np.zeros((mask_height, mask_origin[0]))\n",
    "                right_pad = np.zeros((mask_height, image_width - mask_width - mask_origin[0]))\n",
    "                top_pad = np.zeros((mask_origin[1], image_width))\n",
    "                bottom_pad = np.zeros((image_height - mask_height - mask_origin[1], image_width))\n",
    "\n",
    "                mask = np.hstack((left_pad, mask))\n",
    "                mask = np.hstack((mask, right_pad))\n",
    "                mask = np.vstack((top_pad, mask))\n",
    "                mask = np.vstack((mask, bottom_pad))\n",
    "\n",
    "                # Specifiy instance as a person\n",
    "                category_info = {'id': 1, 'is_crowd': 0}\n",
    "                \n",
    "                annotation_info = pycococreatortools.create_annotation_info(\n",
    "                    instance_id,\n",
    "                    example_id,\n",
    "                    category_info,\n",
    "                    mask,\n",
    "                    (image_width, image_height),\n",
    "                    tolerance=0\n",
    "                )\n",
    "\n",
    "                if annotation_info is not None:\n",
    "                    coco_output['annotations'].append(annotation_info)\n",
    "                    instance_id += 1\n",
    "                    mask_found = True\n",
    "\n",
    "        if mask_found:\n",
    "            try:\n",
    "                image = Image.open(os.path.join(dataset_path, subset, 'img', filename + '.png'))\n",
    "            except:\n",
    "                image = Image.open(os.path.join(dataset_path, subset, 'img', filename + '.jpg'))\n",
    "\n",
    "            # Save image as JPEG with name <dataset>_<filename> to image-train directory\n",
    "            if train:\n",
    "                save_path = os.path.join(output_path, 'image-train', subset + '_' + filename + '.jpg')\n",
    "            else:\n",
    "                save_path = os.path.join(output_path, 'image-test', subset + '_' + filename + '.jpg')\n",
    "            image.save(save_path, format=\"JPEG\")\n",
    "\n",
    "            # Create image info\n",
    "            image_info = pycococreatortools.create_image_info(\n",
    "                example_id,\n",
    "                subset + '_' + filename + '.jpg',\n",
    "                image.size\n",
    "            )\n",
    "\n",
    "            coco_output['images'].append(image_info)\n",
    "        \n",
    "        if (example_id % 100) == 0:\n",
    "            print(f'On example {example_id} of {len(examples)}.')\n",
    "            \n",
    "    return coco_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On example 0 of 3997.\n",
      "On example 100 of 3997.\n",
      "On example 200 of 3997.\n",
      "On example 300 of 3997.\n",
      "On example 400 of 3997.\n",
      "On example 500 of 3997.\n",
      "On example 600 of 3997.\n",
      "On example 700 of 3997.\n",
      "On example 800 of 3997.\n",
      "On example 900 of 3997.\n",
      "On example 1000 of 3997.\n",
      "On example 1100 of 3997.\n",
      "On example 1200 of 3997.\n",
      "On example 1300 of 3997.\n",
      "On example 1400 of 3997.\n",
      "On example 1500 of 3997.\n",
      "On example 1600 of 3997.\n",
      "On example 1700 of 3997.\n",
      "On example 1800 of 3997.\n",
      "On example 1900 of 3997.\n",
      "On example 2000 of 3997.\n",
      "On example 2100 of 3997.\n",
      "On example 2200 of 3997.\n",
      "On example 2300 of 3997.\n",
      "On example 2400 of 3997.\n",
      "On example 2500 of 3997.\n",
      "On example 2600 of 3997.\n",
      "On example 2700 of 3997.\n",
      "On example 2800 of 3997.\n",
      "On example 2900 of 3997.\n",
      "On example 3000 of 3997.\n",
      "On example 3100 of 3997.\n",
      "On example 3200 of 3997.\n",
      "On example 3300 of 3997.\n",
      "On example 3400 of 3997.\n",
      "On example 3500 of 3997.\n",
      "On example 3600 of 3997.\n",
      "On example 3700 of 3997.\n",
      "On example 3800 of 3997.\n",
      "On example 3900 of 3997.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(parent_dir, dataset_dir)\n",
    "\n",
    "coco_train_output = generate_coco_dataset(INFO, LICENSES, CATEGORIES,\n",
    "                                          train_examples,\n",
    "                                          dataset_path, output_dir,\n",
    "                                          train=True)\n",
    "\n",
    "with open(os.path.join(output_dir, 'annotations', 'instances_supervisely_train.json'), 'w') as f:\n",
    "        json.dump(coco_train_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On example 0 of 1714.\n",
      "On example 100 of 1714.\n",
      "On example 200 of 1714.\n",
      "On example 300 of 1714.\n",
      "On example 400 of 1714.\n",
      "On example 500 of 1714.\n",
      "On example 600 of 1714.\n",
      "On example 700 of 1714.\n",
      "On example 800 of 1714.\n",
      "On example 900 of 1714.\n",
      "On example 1000 of 1714.\n",
      "On example 1100 of 1714.\n",
      "On example 1200 of 1714.\n",
      "On example 1300 of 1714.\n",
      "On example 1400 of 1714.\n",
      "On example 1500 of 1714.\n",
      "On example 1600 of 1714.\n",
      "On example 1700 of 1714.\n"
     ]
    }
   ],
   "source": [
    "coco_test_output = generate_coco_dataset(INFO, LICENSES, CATEGORIES,\n",
    "                                          test_examples,\n",
    "                                          dataset_path, output_dir,\n",
    "                                          train=False)\n",
    "\n",
    "with open(os.path.join(output_dir, 'annotations', 'instances_supervisely_test.json'), 'w') as f:\n",
    "        json.dump(coco_test_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864 train images with 1101 annotations.\n",
      "384 test images with 485 annotations.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(coco_train_output['images'])} train images with {len(coco_train_output['annotations'])} annotations.\")\n",
    "print(f\"{len(coco_test_output['images'])} test images with {len(coco_test_output['annotations'])} annotations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
